{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from importlib import import_module\n",
    "from multiprocessing import Lock, Pool\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.ndimage import measurements\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage.segmentation import watershed\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataloader.train_loader import FileLoader\n",
    "from misc.utils import get_bounding_box, remove_small_objects\n",
    "from models.hovernet.net_desc import create_model\n",
    "from models.hovernet.targets import gen_targets\n",
    "from run_utils.utils import convert_pytorch_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conic_model = create_model(\n",
    "    num_types=7, pretrained_backbone=\"exp_output/local/resnet50-0676ba61.pth\"\n",
    ")\n",
    "checkpoint = torch.load(\n",
    "    \"exp_output/local/models/baseline/00/model/00/net_epoch=50.tar\",\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")\n",
    "conic_model.load_state_dict(convert_pytorch_checkpoint(checkpoint[\"desc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileloader = FileLoader(\n",
    "    \"exp_output/local/data/images.npy\",\n",
    "    \"exp_output/local/data/labels.npy\",\n",
    "    with_type=True,\n",
    "    input_shape=[256, 256],\n",
    "    mask_shape=[256, 256],\n",
    "    run_mode=\"infer\",\n",
    "    target_gen_func=[gen_targets, {}],\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    fileloader,\n",
    "    num_workers=1,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_step(batch_data, model):\n",
    "    ####\n",
    "    patch_imgs = batch_data\n",
    "\n",
    "    patch_imgs_gpu = patch_imgs.type(torch.float32)  # to NCHW\n",
    "    patch_imgs_gpu = patch_imgs_gpu.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "    ####\n",
    "    model.eval()  # infer mode\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    with torch.no_grad():  # dont compute gradient\n",
    "        pred_dict = model(patch_imgs_gpu)\n",
    "        pred_dict = OrderedDict(\n",
    "            [[k, v.permute(0, 2, 3, 1).contiguous()] for k, v in pred_dict.items()]\n",
    "        )\n",
    "        pred_dict[\"np\"] = F.softmax(pred_dict[\"np\"], dim=-1)[..., 1:]\n",
    "        if \"tp\" in pred_dict:\n",
    "            type_map = F.softmax(pred_dict[\"tp\"], dim=-1)\n",
    "            type_map = torch.argmax(type_map, dim=-1, keepdim=True)\n",
    "            type_map = type_map.type(torch.float32)\n",
    "            pred_dict[\"tp\"] = type_map\n",
    "        pred_output = torch.cat(list(pred_dict.values()), -1)\n",
    "\n",
    "    # * Its up to user to define the protocol to process the raw output per step!\n",
    "    return pred_output.cpu().numpy()\n",
    "\n",
    "def noop(*args, **kargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = noop\n",
    "\n",
    "def __proc_np_hv(pred):\n",
    "    \"\"\"Process Nuclei Prediction with XY Coordinate Map.\n",
    "\n",
    "    Args:\n",
    "        pred: prediction output, assuming\n",
    "              channel 0 contain probability map of nuclei\n",
    "              channel 1 containing the regressed X-map\n",
    "              channel 2 containing the regressed Y-map\n",
    "\n",
    "    \"\"\"\n",
    "    pred = np.array(pred, dtype=np.float32)\n",
    "\n",
    "    blb_raw = pred[..., 0]\n",
    "    h_dir_raw = pred[..., 1]\n",
    "    v_dir_raw = pred[..., 2]\n",
    "\n",
    "    # processing\n",
    "    blb = np.array(blb_raw >= 0.5, dtype=np.int32)\n",
    "\n",
    "    blb = measurements.label(blb)[0]\n",
    "    blb = remove_small_objects(blb, min_size=10)\n",
    "    blb[blb > 0] = 1  # background is 0 already\n",
    "\n",
    "    h_dir = cv2.normalize(\n",
    "        h_dir_raw, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "    )\n",
    "    v_dir = cv2.normalize(\n",
    "        v_dir_raw, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "    )\n",
    "\n",
    "    sobelh = cv2.Sobel(h_dir, cv2.CV_64F, 1, 0, ksize=21)\n",
    "    sobelv = cv2.Sobel(v_dir, cv2.CV_64F, 0, 1, ksize=21)\n",
    "\n",
    "    sobelh = 1 - (\n",
    "        cv2.normalize(\n",
    "            sobelh, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "        )\n",
    "    )\n",
    "    sobelv = 1 - (\n",
    "        cv2.normalize(\n",
    "            sobelv, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F\n",
    "        )\n",
    "    )\n",
    "\n",
    "    overall = np.maximum(sobelh, sobelv)\n",
    "    overall = overall - (1 - blb)\n",
    "    overall[overall < 0] = 0\n",
    "\n",
    "    dist = (1.0 - overall) * blb\n",
    "    ## nuclei values form mountains so inverse to get basins\n",
    "    dist = -cv2.GaussianBlur(dist, (3, 3), 0)\n",
    "\n",
    "    overall = np.array(overall >= 0.4, dtype=np.int32)\n",
    "\n",
    "    marker = blb - overall\n",
    "    marker[marker < 0] = 0\n",
    "    marker = binary_fill_holes(marker).astype(\"uint8\")\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    marker = cv2.morphologyEx(marker, cv2.MORPH_OPEN, kernel)\n",
    "    marker = measurements.label(marker)[0]\n",
    "    marker = remove_small_objects(marker, min_size=10)\n",
    "\n",
    "    proced_pred = watershed(dist, markers=marker, mask=blb)\n",
    "\n",
    "    return proced_pred\n",
    "\n",
    "def process(\n",
    "    pred_map,\n",
    "    nr_types=None,\n",
    "    return_centroids=False,\n",
    "):\n",
    "    \"\"\"Post processing script for image tiles.\n",
    "\n",
    "    Args:\n",
    "        pred_map: commbined output of tp, np and hv branches, in the same order\n",
    "        nr_types: number of types considered at output of nc branch\n",
    "        overlaid_img: img to overlay the predicted instances upon, `None` means no\n",
    "        type_colour (dict) : `None` to use random, else overlay instances of a type to colour in the dict\n",
    "        output_dtype: data type of output\n",
    "\n",
    "    Returns:\n",
    "        pred_inst:     pixel-wise nuclear instance segmentation prediction\n",
    "        pred_type_out: pixel-wise nuclear type prediction\n",
    "\n",
    "    \"\"\"\n",
    "    if nr_types is not None:\n",
    "        pred_type = pred_map[..., :1]\n",
    "        pred_inst = pred_map[..., 1:]\n",
    "        pred_type = pred_type.astype(np.int32)\n",
    "    else:\n",
    "        pred_inst = pred_map\n",
    "\n",
    "    pred_inst = np.squeeze(pred_inst)\n",
    "    pred_inst = __proc_np_hv(pred_inst)\n",
    "\n",
    "    inst_info_dict = None\n",
    "    if return_centroids or nr_types is not None:\n",
    "        inst_id_list = np.unique(pred_inst)[1:]  # exlcude background\n",
    "        inst_info_dict = {}\n",
    "        for inst_id in inst_id_list:\n",
    "            inst_map = pred_inst == inst_id\n",
    "            # TODO: chane format of bbox output\n",
    "            rmin, rmax, cmin, cmax = get_bounding_box(inst_map)\n",
    "            inst_bbox = np.array([[rmin, cmin], [rmax, cmax]])\n",
    "            inst_map = inst_map[\n",
    "                inst_bbox[0][0] : inst_bbox[1][0], inst_bbox[0][1] : inst_bbox[1][1]\n",
    "            ]\n",
    "            inst_map = inst_map.astype(np.uint8)\n",
    "            inst_moment = cv2.moments(inst_map)\n",
    "            inst_contour = cv2.findContours(\n",
    "                inst_map, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "            )\n",
    "            # * opencv protocol format may break\n",
    "            inst_contour = np.squeeze(inst_contour[0][0].astype(\"int32\"))\n",
    "            # < 3 points dont make a contour, so skip, likely artifact too\n",
    "            # as the contours obtained via approximation => too small or sthg\n",
    "            if inst_contour.shape[0] < 3:\n",
    "                continue\n",
    "            if len(inst_contour.shape) != 2:\n",
    "                continue  # ! check for trickery shape\n",
    "            inst_centroid = [\n",
    "                (inst_moment[\"m10\"] / inst_moment[\"m00\"]),\n",
    "                (inst_moment[\"m01\"] / inst_moment[\"m00\"]),\n",
    "            ]\n",
    "            inst_centroid = np.array(inst_centroid)\n",
    "            inst_contour[:, 0] += inst_bbox[0][1]  # X\n",
    "            inst_contour[:, 1] += inst_bbox[0][0]  # Y\n",
    "            inst_centroid[0] += inst_bbox[0][1]  # X\n",
    "            inst_centroid[1] += inst_bbox[0][0]  # Y\n",
    "            inst_info_dict[inst_id] = {  # inst_id should start at 1\n",
    "                \"bbox\": inst_bbox,\n",
    "                \"centroid\": inst_centroid,\n",
    "                \"contour\": inst_contour,\n",
    "                \"type_prob\": None,\n",
    "                \"type\": None,\n",
    "            }\n",
    "\n",
    "    if nr_types is not None:\n",
    "        #### * Get class of each instance id, stored at index id-1\n",
    "        for inst_id in list(inst_info_dict.keys()):\n",
    "            rmin, cmin, rmax, cmax = (inst_info_dict[inst_id][\"bbox\"]).flatten()\n",
    "            inst_map_crop = pred_inst[rmin:rmax, cmin:cmax]\n",
    "            inst_type_crop = pred_type[rmin:rmax, cmin:cmax]\n",
    "            inst_map_crop = (\n",
    "                inst_map_crop == inst_id\n",
    "            )  # TODO: duplicated operation, may be expensive\n",
    "            inst_type = inst_type_crop[inst_map_crop]\n",
    "            type_list, type_pixels = np.unique(inst_type, return_counts=True)\n",
    "            type_list = list(zip(type_list, type_pixels))\n",
    "            type_list = sorted(type_list, key=lambda x: x[1], reverse=True)\n",
    "            inst_type = type_list[0][0]\n",
    "            if inst_type == 0:  # ! pick the 2nd most dominant if exist\n",
    "                if len(type_list) > 1:\n",
    "                    inst_type = type_list[1][0]\n",
    "            type_dict = {v[0]: v[1] for v in type_list}\n",
    "            type_prob = type_dict[inst_type] / (np.sum(inst_map_crop) + 1.0e-6)\n",
    "            inst_info_dict[inst_id][\"type\"] = int(inst_type)\n",
    "            inst_info_dict[inst_id][\"type_prob\"] = float(type_prob)\n",
    "\n",
    "    # print('here')\n",
    "    # ! WARNING: ID MAY NOT BE CONTIGUOUS\n",
    "    # inst_id in the dict maps to the same value in the `pred_inst`\n",
    "    return pred_inst, inst_info_dict\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"Generate random colors.\n",
    "\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def visualize_instances_dict(\n",
    "    input_image, inst_dict, draw_dot=False, type_colour=None, line_thickness=2\n",
    "):\n",
    "    \"\"\"Overlays segmentation results (dictionary) on image as contours.\n",
    "\n",
    "    Args:\n",
    "        input_image: input image\n",
    "        inst_dict: dict of output prediction, defined as in this library\n",
    "        draw_dot: to draw a dot for each centroid\n",
    "        type_colour: a dict of {type_id : (type_name, colour)} ,\n",
    "                     `type_id` is from 0-N and `colour` is a tuple of (R, G, B)\n",
    "        line_thickness: line thickness of contours\n",
    "    \"\"\"\n",
    "    overlay = np.copy((input_image))\n",
    "\n",
    "    inst_rng_colors = random_colors(len(inst_dict))\n",
    "    inst_rng_colors = np.array(inst_rng_colors) * 255\n",
    "    inst_rng_colors = inst_rng_colors.astype(np.uint8)\n",
    "\n",
    "    for idx, [inst_id, inst_info] in enumerate(inst_dict.items()):\n",
    "        inst_contour = inst_info[\"contour\"]\n",
    "        if \"type\" in inst_info and type_colour is not None:\n",
    "            inst_colour = type_colour[inst_info[\"type\"]][1]\n",
    "        else:\n",
    "            inst_colour = (inst_rng_colors[idx]).tolist()\n",
    "        cv2.drawContours(overlay, [inst_contour], -1, inst_colour, line_thickness)\n",
    "\n",
    "        if draw_dot:\n",
    "            inst_centroid = inst_info[\"centroid\"]\n",
    "            inst_centroid = tuple([int(v) for v in inst_centroid])\n",
    "            overlay = cv2.circle(overlay, inst_centroid, 3, (255, 0, 0), -1)\n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_iterator = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, tp_map, hv_map, np_map = next(image_iterator).values()\n",
    "pred_img = infer_step(img.to('cpu'), conic_model.to('cpu'))\n",
    "instance_info = process(pred_img[0], nr_types=7, return_centroids=True)\n",
    "\n",
    "visualization_img = visualize_instances_dict(\n",
    "    img[0],\n",
    "    instance_info[1],\n",
    "    draw_dot=False,\n",
    "    line_thickness=2,\n",
    "    type_colour={\n",
    "        0: [\"nolabe\", [0, 0, 0]],\n",
    "        1: [\"neutrophil\", [245, 119, 54]],\n",
    "        2: [\"epithelial\", [0, 223, 54]],\n",
    "        3: [\"lymphocyte\", [255, 0, 8]],\n",
    "        4: [\"plasma\", [0, 193, 252]],\n",
    "        5: [\"eosinophil\", [0, 86, 197]],\n",
    "        6: [\"connective\", [223, 221, 151]],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouth_truth = torch.concat([tp_map.unsqueeze(-1), np_map.unsqueeze(-1), hv_map], dim=-1)\n",
    "grouth_truth_instance_info = process(grouth_truth[0].numpy(), nr_types=7, return_centroids=True)\n",
    "\n",
    "visualization_img_grouth_truth = visualize_instances_dict(\n",
    "    img[0],\n",
    "    grouth_truth_instance_info[1],\n",
    "    draw_dot=False,\n",
    "    line_thickness=2,\n",
    "    type_colour={\n",
    "        0: [\"nolabe\", [0, 0, 0]],\n",
    "        1: [\"neutrophil\", [245, 119, 54]],\n",
    "        2: [\"epithelial\", [0, 223, 54]],\n",
    "        3: [\"lymphocyte\", [255, 0, 8]],\n",
    "        4: [\"plasma\", [0, 193, 252]],\n",
    "        5: [\"eosinophil\", [0, 86, 197]],\n",
    "        6: [\"connective\", [223, 221, 151]],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, 2, figsize=(15, 15), dpi=400)\n",
    "axes[0].imshow(visualization_img_grouth_truth)\n",
    "axes[1].imshow(visualization_img)\n",
    "\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[1].set_title('Prediction')\n",
    "axes[0].set_axis_off()\n",
    "axes[1].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_statistics = [0 for i in range(7)]\n",
    "for i in instance_info[1].values():\n",
    "    type_statistics[int(i[\"type\"])] += 1\n",
    "\n",
    "\n",
    "type_statistics_grouth_truth = [0 for i in range(7)]\n",
    "for i in grouth_truth_instance_info[1].values():\n",
    "    type_statistics_grouth_truth[int(i[\"type\"])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_colour={\n",
    "    0: [\"nolabe\", [0, 0, 0]],\n",
    "    1: [\"neutrophil\", [245, 119, 54]],\n",
    "    2: [\"epithelial\", [0, 223, 54]],\n",
    "    3: [\"lymphocyte\", [255, 0, 8]],\n",
    "    4: [\"plasma\", [0, 193, 252]],\n",
    "    5: [\"eosinophil\", [0, 86, 197]],\n",
    "    6: [\"connective\", [223, 221, 151]],\n",
    "}\n",
    "\n",
    "print('Number of cells and type statistics')\n",
    "print(f'Total cell: {len(instance_info[1].values())}, {len(grouth_truth_instance_info[1].values())}')\n",
    "total_cell = 0\n",
    "for idx, value in enumerate(type_statistics):\n",
    "    data = type_colour[idx]\n",
    "    data_ground_truth = type_colour[idx]\n",
    "    print(f'{data[0]} = {value, type_statistics_grouth_truth[idx]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hovernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
